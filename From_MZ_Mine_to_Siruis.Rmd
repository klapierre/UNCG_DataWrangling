---
title: "From MZ Mine to Siruis: How to Tidy Your Data"
author: "Stephanie Mota"
date: "2023-04-28"
output: pdf_document
---

## Overview
The data set I am working on is a mass spectrometry analysis of the different compounds found in the plant extracts I am working with. We call this, metabolomics data. I want to know which compound in my extracts is responsible for the antimicrobial activity it shows when tested in an antimicrobial bioassay. But mass spectrometry is not limited to the world biochemistry. Mass spectrometry is a tool used to help identify different compounds in a sample. This sample can range from plant extracts, water samples, soil samples, and more. To figure out what compound is responsible, first I need to sort through which molecules are from the solvent the sample was dissolved in and which molecules are just noise/insignificant/not real.
\
\
There are 2 main parts to how the lab has devised how to filter through the data: There is the metabolomics analysis and then there is the modeling in Sirius. The metabolomics analysis has 4 parts to it: 1) Features, 2) Blank Filter, 3) RSD Filter, and 4) Metabolomics analysis. The modeling in Sirius is what helps generate the figures we need. In this workflow, I will be focusing on the first part which is the bulk of the work and analyzing. If there is time, I will also include the part that generates the figures but that is done using a different program.
\
\
### Preparations
Like everything, there are a couple things we need to do first before we can jump right into our coding. First we need to load the packages we are going to be using. Then we need to load the files we will be working with.

```{r Load Packages}
library(tidyr)
library(tidyverse)
library(dplyr)
```

Here we are loading and merging the positive and negative modes of our mass spectrometry data:

```{r Loading and Merging The Positive and Negative Modes}

Tulip_C4Fractions_POS <- read.csv("https://raw.githubusercontent.com/klapierre/UNCG_DataWrangling/MotaStephanie/220713_Tulip_C4Fractions_POS.csv")
colnames(Tulip_C4Fractions_POS)<-gsub(".mzML.crop_filtered_POS.Peak.area","",colnames(Tulip_C4Fractions_POS))

Tulip_C4Fractions_NEG <- read.csv("https://raw.githubusercontent.com/klapierre/UNCG_DataWrangling/MotaStephanie/220713_Tulip_C4Fractions_NEG.csv") 
colnames(Tulip_C4Fractions_NEG)<-gsub(".mzML.crop_filtered_NEG.Peak.area","",colnames(Tulip_C4Fractions_NEG))

Tulip_C4Fractions_POSNEG <- bind_rows(Tulip_C4Fractions_POS, Tulip_C4Fractions_NEG)

remove(Tulip_C4Fractions_NEG)
remove(Tulip_C4Fractions_POS)

```
\
Depending on what you are working with, you may wish to omit the merging of the two dataframes. I chose to merge them because all data points are important to look at. Some molecules may appear in the positive mode which do not appear in the negative mode and vice versa. This is simply because of the charge they have when they are getting filtered through the machine. Either way, it takes both positive and negative ions to make up the whole sample which we analyze. So for this set of data, I will be merging the dataframes.
\
\
### Features
Now that we have our dataframes, let's create our features list. What is a feature? A feature is the m/z value of the molecule combined with its retention time. Retention time is the time the molecule came out of the sample and into the machine. This is what we will use to identify the molecules found in the samples.

```{r Create Features List}
FeaturesList <- Tulip_C4Fractions_POSNEG %>% 
  mutate(row.m.z = round(row.m.z, digits = 4),
         row.retention.time = round(row.retention.time, digits = 2),
         Features = paste(row.m.z, row.retention.time, sep = "-")) %>% 
   relocate(Features, .before = row.ID) %>% 
  select(-row.m.z, 
         -row.ID, 
         -row.retention.time,
         -X) 

remove(Tulip_C4Fractions_POSNEG)
```

With our Features List, we are going to filter out the values which 1) too low and 2) are too similar to our blanks. 
\
If the values are too low, they are considered insignificant to work with and thus cannot be used to make a statistically accurate analysis. If the values are too similar too similar to our blanks, then we are looking at the blanks. 
\
Allow me to elaborate. We dissolve our sample in the solvent (or solvents) of our choosing so that they may be processed by the LC-MS. We run the solvent(s) as a blank so that we can cancel it out later in this process. After all, we do not wish to analyze the solvent which our sample was dissolved in.
\
\
The code below can be adjusted to fit what you have decided to name your samples and blanks. In the second set of mutate functions, I am doing math using the names of the columns. My samples contain "LT.C4" in their name, so I will filter out my samples using that keyword. I do the same with the two blanks I ran. Should you find yourself needing to use this code for your own data, those would be the lines of code which would need some adjustment.


```{r Filtering Out Blanks}
BlankFilterMath <- FeaturesList %>% 
  mutate(MeanALL = rowMeans(across(-1)),
         SDALL = apply(FeaturesList[, -1], 1, sd, na.rm=T),
         RSD = SDALL/MeanALL*100) %>% 
  filter(RSD>30) %>% 
  mutate(MeanSamples = rowMeans(select(., contains("LT.C4")), na.rm=T),
         MeanBlanks = rowMeans(select(., contains("zBLK")), na.rm=T),
         MeanPblanks = rowMeans(select(., contains("PROCBLANK")), na.rm=T),
         "PBlank/Sample" = MeanPblanks/MeanSamples*100,
         "WBlank/Sample" = MeanBlanks/MeanSamples*100) %>% 
  filter("PBlank/Sample" > 80) %>% 
  filter("WBlank/Sample" > 80)

remove(FeaturesList)

BlankFiltered <- BlankFilterMath %>% 
  select(Features,
         contains("LT.C4"))

remove(BlankFilterMath)
```

### RSD Filtered
/
This is the hardest part of the coding. With that said, I could not make this a generic code which could be used across data frames.
/
I am so sorry, there was no way to make this part clean. The code is long and most of it is done column by column. Ideally, this would have been done using a couple, simple lines of code. Maybe after learning how to do matrix math, aggregate, and other complex code and new packages. I simply lost the will to continue and made this code work in my own special way.

```{r RSD Filtered}
RSDFiltered2 <- BlankFiltered %>% 
  mutate(LT.C4.1 = (apply(select(., contains("LT.C4.1")), 1, sd, na.rm=T))/(rowMeans(select(., contains("LT.C4.1")), na.rm=T)),
         LT.C4.2 = (apply(select(., contains("LT.C4.2")), 1, sd, na.rm=T))/(rowMeans(select(., contains("LT.C4.2")), na.rm=T)),
         LT.C4.3 = (apply(select(., contains("LT.C4.3")), 1, sd, na.rm=T))/(rowMeans(select(., contains("LT.C4.3")), na.rm=T)),
         LT.C4.4 = (apply(select(., contains("LT.C4.4")), 1, sd, na.rm=T))/(rowMeans(select(., contains("LT.C4.4")), na.rm=T)),
         LT.C4.5 = (apply(select(., contains("LT.C4.5")), 1, sd, na.rm=T))/(rowMeans(select(., contains("LT.C4.5")), na.rm=T)),
         LT.C4.6 = (apply(select(., contains("LT.C4.6")), 1, sd, na.rm=T))/(rowMeans(select(., contains("LT.C4.6")), na.rm=T)),
         LT.C4.7 = (apply(select(., contains("LT.C4.7")), 1, sd, na.rm=T))/(rowMeans(select(., contains("LT.C4.7")), na.rm=T))) %>% 
  select(Features, 
         LT.C4.1, 
         LT.C4.2, 
         LT.C4.3, 
         LT.C4.4,
         LT.C4.5,
         LT.C4.6,
         LT.C4.7) %>% 
  mutate(across(where(is.numeric), ~ifelse(.>0.35, 0, .))) %>% 
  replace(is.na(.), 0)


RSDFiltered3 <- BlankFiltered %>% 
  mutate(LT.C4.1 = (rowMeans(select(., contains("LT.C4.1")), na.rm=T)),
         LT.C4.2 = (rowMeans(select(., contains("LT.C4.2")), na.rm=T)),
         LT.C4.3 = (rowMeans(select(., contains("LT.C4.3")), na.rm=T)),
         LT.C4.4 = (rowMeans(select(., contains("LT.C4.4")), na.rm=T)),
         LT.C4.5 = (rowMeans(select(., contains("LT.C4.5")), na.rm=T)),
         LT.C4.6 = (rowMeans(select(., contains("LT.C4.6")), na.rm=T)),
         LT.C4.7 = (rowMeans(select(., contains("LT.C4.7")), na.rm=T)))%>% 
  select(Features, 
         LT.C4.1, 
         LT.C4.2, 
         LT.C4.3, 
         LT.C4.4,
         LT.C4.5,
         LT.C4.6,
         LT.C4.7)

RSDFiltered5 <- merge(RSDFiltered2, RSDFiltered3, by = "Features") %>% 
  mutate(LT.C4.1.y = ifelse(LT.C4.1.x == 0, NA, LT.C4.1.y),
         LT.C4.2.y = ifelse(LT.C4.2.x == 0, NA, LT.C4.2.y),
         LT.C4.3.y = ifelse(LT.C4.3.x == 0, NA, LT.C4.3.y),
         LT.C4.4.y = ifelse(LT.C4.4.x == 0, NA, LT.C4.4.y),
         LT.C4.5.y = ifelse(LT.C4.5.x == 0, NA, LT.C4.5.y),
         LT.C4.6.y = ifelse(LT.C4.6.x == 0, NA, LT.C4.6.y),
         LT.C4.7.y = ifelse(LT.C4.7.x == 0, NA, LT.C4.7.y)) %>% 
  select(-contains("x")) %>% 
  replace(is.na(.), 0) %>% 
  filter(rowMeans(.[,-1]) != 0)


RSDFiltered9 <- t(RSDFiltered5) 
print(RSDFiltered9)
```

***Metabolomics Analysis
Now the data is ready to be exported to Sirius where we can do some figure generation. The program Sirius is commonly used but not in America. It is a paid program used in Europe which helps comparing all the many different compounds found (there's a LOT even after filtering through them) with the fractions showing antimicrobial activity a lot easier. I believe it is used for other types of analysis, but I am not well versed in the program itself to say what kinds of analysis and how to do them.
\
\
These figures include, but are not limited to: a scores and loadings plot and a selectivity ratio plot.
\
\
In figure 1, there are graphs: one with few points and another with much more points. The one with few points ranks the significance of the fraction in its antimicrobial activity. The other does the same but with the compounds found in the fractions.
\
Figure 2 shows the selectivity ratio plot generated with the same information. It is a bar graph which visualizes the antimicrobial activity of the compounds.

